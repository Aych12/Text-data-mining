---
title: "bot dection"
author: "Chuhan Yue"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
library(httr)
library(rvest)
library(xml2)
library(quanteda)
library("quanteda.textplots")
library("quanteda.textstats")
library(plotly)
library(sentimentr)
```

```{r}
# 设置 URL 和前缀
url <- 'https://www.rottentomatoes.com/tv/a_murder_at_the_end_of_the_world/s01/reviews'
user_agent <- 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

# send HTTP requirment，set User-Agent
response <- GET(url, add_headers('User-Agent' = user_agent))

# extract HTML content
html_content <- content(response, as = 'text')

# 使用 rvest 创建一个 HTML 会话
session <- html_session(url, user_agent(user_agent))

# 使用 html_nodes 查找标签
text_nodes <- html_nodes(session, 'p.review-text')


review_texts <- xml_text(text_nodes)

# 创建数据框
df <- data.frame(Review = review_texts)
```

```{r}
docs_1<- tolower(review_texts)%>%lemmatize_words()
docs_2 <- corpus(docs_1)
docs_3 <- quanteda::tokens(docs_2,remove_punct = TRUE, remove_numbers = TRUE)
sw <- stopwords("english") 
docs_3<-tokens_remove(docs_3, sw)%>%dfm()
```

```{r}
doc_freq <- docfreq(docs_3)
toks_2 <- dfm_trim(docs_3,min_termfreq=2,max_termfreq = 100, min_docfreq = 2)
topfeatures(toks_2, 20)
```
```{r}
set.seed(100)
textplot_wordcloud(toks_2, min_size = 0.000001,
                   color = RColorBrewer::brewer.pal(8, "Dark2"))
```
```{R}
tstat_freq_inaug <- textstat_frequency(toks_2, n = 100)

ggplot(tstat_freq_inaug, aes(x = frequency, y = reorder(feature, frequency))) +
    geom_point() + 
    labs(x = "Frequency", y = "Feature")
```
```{r}

sentiment_scores <- sentiment_by(as.character(df), by = NULL)
sentiment_scores
```